{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fgWICC-FA0B"
      },
      "outputs": [],
      "source": [
        "# install yfinance\n",
        "!pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries \n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "import os\n",
        "import json\n",
        "import datetime\n",
        "from datetime import date,timedelta\n",
        "import warnings\n",
        "import http.client, urllib.parse\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification,pipeline\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.max_rows', 500)\n",
        "\n",
        "# company symbol and name\n",
        "company_symbol=\"RELIANCE.NS\"\n",
        "\n",
        "#initialise today date\n",
        "today = str(date.today())\n",
        "yesterday = str(date.today()- timedelta(days = 1))\n",
        "\n",
        "# flag variables\n",
        "news_inserted=False\n",
        "\n",
        "#secret keys of mediastack \n",
        "user_secrets = UserSecretsClient()\n",
        "mediastack_api_token = user_secrets.get_secret(\"mediastack-token\")\n",
        "\n",
        "# input file paths\n",
        "stock_history_file_path='../input/reliancestockandnewsdata/reliance_stock_history.csv'\n",
        "news_file_path='../input/reliancestockandnewsdata/reliance_news.json'\n",
        "news_sentiment_file_path='../input/reliancestockandnewsdata/reliance_news_sentiment.csv'\n",
        "\n",
        "# output file paths\n",
        "output_stock_history_file_path='./reliance_stock_history.csv'\n",
        "output_news_file_path='./reliance_news.json'\n",
        "output_news_sentiment_file_path='./reliance_news_sentiment.csv'\n",
        "\n",
        "# parameters for mediastack api\n",
        "search_query='reliance'\n",
        "conn = http.client.HTTPConnection('api.mediastack.com')\n",
        "params = urllib.parse.urlencode({\n",
        "    'keywords': search_query,\n",
        "    'access_key': mediastack_api_token,\n",
        "    'sort': 'published_desc',\n",
        "    'limit': 10,\n",
        "    'languages': 'en',\n",
        "    'country': 'in',\n",
        "    'date': yesterday\n",
        "    })"
      ],
      "metadata": {
        "id": "uOQsbikqFE3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_stock_history_dataset():\n",
        "    reliance_stock_history=ticker_object.history(period=\"1d\").reset_index()\n",
        "    return reliance_stock_history\n",
        "\n",
        "def update_stock_history_dataset():\n",
        "    reliance_stock_history=pd.read_csv(stock_history_file_path)\n",
        "    reliance_stock_history.Date=pd.to_datetime(reliance_stock_history.Date, format='%Y/%m/%d')\n",
        "    today_reliance_stock_data=ticker_object.history(period=\"1d\")\n",
        "    today_reliance_stock_data=today_reliance_stock_data.reset_index()\n",
        "    last_stock_date=str(today_reliance_stock_data.loc[0,'Date']).split()[0]\n",
        "    if last_stock_date == reliance_stock_history['Date'].dt.strftime('%Y-%m-%d')[len(reliance_stock_history)-1]: #if already inserted \n",
        "        reliance_stock_history.iloc[-1:,:]=today_reliance_stock_data.iloc[-1].tolist()\n",
        "    else:\n",
        "        last_position=len(reliance_stock_history)\n",
        "        reliance_stock_history.loc[last_position]=today_reliance_stock_data.iloc[-1].tolist()\n",
        "    return reliance_stock_history"
      ],
      "metadata": {
        "id": "_j-iAivMFPuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create stock market history dataset\n",
        "ticker_object=yf.Ticker(company_symbol)\n",
        "if os.path.exists(stock_history_file_path)==False:\n",
        "    reliance_stock_history=create_stock_history_dataset()\n",
        "else:\n",
        "    reliance_stock_history=update_stock_history_dataset()\n",
        "\n",
        "\n",
        "reliance_stock_history.to_csv(output_stock_history_file_path,index=False)"
      ],
      "metadata": {
        "id": "WiNR4HfsFzV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_news_dataset():\n",
        "    conn.request('GET', '/v1/news?{}'.format(params))\n",
        "    res = conn.getresponse().read()\n",
        "    reliance_news=json.loads(res.decode('utf-8'))[\"data\"]\n",
        "    return reliance_news\n",
        "\n",
        "def update_news_dataset():\n",
        "    global news_inserted\n",
        "    with open(news_file_path,'r') as file:\n",
        "        reliance_news=json.load(file)\n",
        "        for news in reliance_news['articles']:\n",
        "            if news['published_at'].split('T')[0]==yesterday:\n",
        "                news_inserted=True\n",
        "                break\n",
        "        current_reliance_news=None\n",
        "        if news_inserted==False:\n",
        "            conn.request('GET', '/v1/news?{}'.format(params))\n",
        "            res = conn.getresponse().read()\n",
        "            current_reliance_news=json.loads(res.decode('utf-8'))[\"data\"]\n",
        "            reliance_news['articles']+=current_reliance_news\n",
        "        return reliance_news['articles'],current_reliance_news"
      ],
      "metadata": {
        "id": "DkzVGbcpF1ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create news dataset \n",
        "if os.path.exists(news_file_path)==False:\n",
        "    reliance_news=create_news_dataset()\n",
        "    current_reliance_news=reliance_news.copy()\n",
        "else:\n",
        "    reliance_news,current_reliance_news=update_news_dataset()\n",
        "\n",
        "with open(output_news_file_path,'w') as file:\n",
        "    json.dump({\"articles\":reliance_news},file)"
      ],
      "metadata": {
        "id": "tnTqIjLJF5rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reliance_news"
      ],
      "metadata": {
        "id": "DBkV3EQVF9Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
        "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "wAZKQKJRF_Fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_news_sentiment_dataset(news_sentiments):\n",
        "    last_position=len(news_sentiments)\n",
        "    article_ind=last_position\n",
        "    title_description=[]\n",
        "    if current_reliance_news!=None:\n",
        "        for article in current_reliance_news:\n",
        "            title_description.append(article['title']+' '+article['description'])\n",
        "            news_sentiments.at[article_ind,'published_at']=article['published_at']\n",
        "            news_sentiments.at[article_ind,'title']=article['title']\n",
        "            news_sentiments.at[article_ind,'description']=article['description']\n",
        "            news_sentiments.at[article_ind,'url']=article['url']\n",
        "            article_ind+=1\n",
        "        news_label_and_scores=classifier(list(title_description))\n",
        "        labels=[pred['label'] for pred in news_label_and_scores]\n",
        "        scores=[pred['score'] for pred in news_label_and_scores]\n",
        "        news_sentiments.at[last_position:,'sentiment']=labels\n",
        "        news_sentiments.at[last_position:,'sentiment_score']=scores\n",
        "    \n",
        "    news_sentiments.to_csv(output_news_sentiment_file_path,index=None)  "
      ],
      "metadata": {
        "id": "1wTOXaikGQSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create news sentiment dataset\n",
        "news_sentiments=None\n",
        "if os.path.exists(news_sentiment_file_path):\n",
        "    news_sentiments=pd.read_csv(news_sentiment_file_path,index_col=None)                     \n",
        "else:\n",
        "    news_sentiments=pd.DataFrame(columns=['published_at','title','description','url','sentiment','sentiment_score'])\n",
        "create_news_sentiment_dataset(news_sentiments)"
      ],
      "metadata": {
        "id": "kBkIFSHMGUEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_sentiments"
      ],
      "metadata": {
        "id": "FttgqiAMGW1f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}